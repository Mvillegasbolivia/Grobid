<?xml version="1.0" ?>
<tei type="conference-article">
	<teiHeader>
		<fileDesc xml:id="55113689"/>
	</teiHeader>
	<text xml:lang="en">
		<front>
<lb/>
	<docTitle>
	<titlePart>Pipelined Back-Propagation for Context-Dependent Deep Neural Networks<lb/></titlePart>
	</docTitle>

	<byline>
	<docAuthor>Xie Chen<lb/> 1,3 , Adam Eversole<lb/> 2 , Gang Li<lb/> 1 , Dong Yu<lb/> 2 , and Frank Seide<lb/> 1<lb/></docAuthor>
	</byline>

	<byline>
	<affiliation>1 Microsoft Research Asia,</affiliation>
	</byline>

	<address>Beijing, P.R.C.<lb/></address>

	<byline>
	<affiliation>2 Microsoft Research,</affiliation>
	</byline>

	<address>Redmond, USA<lb/></address>

	<byline>
	<affiliation>3 Department of Electronic Engineering, Tsinghua University,</affiliation>
	</byline>

	<address>10084 Beijing, P.R.C.<lb/></address>

	<email>{adame,ganl,dongyu,fseide}@microsoft.com<lb/></email>

	<div type="abstract">Abstract<lb/> The Context-Dependent Deep-Neural-Network HMM, or CD-<lb/>DNN-HMM, is a recently proposed acoustic-modeling tech-<lb/>nique for HMM-based speech recognition that can greatly out-<lb/>perform conventional Gaussian-mixture based HMMs. For ex-<lb/>ample, a CD-DNN-HMM trained on the 2000h Fisher corpus<lb/> achieves 14.4% word error rate on the Hub5&apos;00-FSH speaker-<lb/>independent phone-call transcription task, compared to 19.6%<lb/> obtained by a state-of-the-art, conventional discriminatively<lb/> trained GMM-based HMM.<lb/> That CD-DNN-HMM, however, took 59 days to train on a<lb/> modern GPGPUâ€”the immense computational cost of the mini-<lb/>batch based back-propagation (BP) training is a major road-<lb/>block. Unlike the familiar Baum-Welch training for conven-<lb/>tional HMMs, BP cannot be efficiently parallelized across data.<lb/> In this paper we show that the pipelined approximation to<lb/> BP, which parallelizes computation with respect to layers, is<lb/> an efficient way of utilizing multiple GPGPU cards in a single<lb/> server. Using 2 and 4 GPGPUs, we achieve a 1.9 and 3.3 times<lb/> end-to-end speed-up, at parallelization efficiency of 0.95 and<lb/> 0.82, respectively, at no loss of recognition accuracy.<lb/></div>

	<keyword>Index Terms: speech recognition, deep neural networks, paral-<lb/>lelization, GPGPU<lb/></keyword>

		</front>
	</text>
</tei>
